{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 100\n",
    "mpl.rcParams[\"savefig.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "max_age = 101\n",
    "age_limits = list(range(max_age))\n",
    "\n",
    "test_split = 0.1\n",
    "valid_split = 0.1\n",
    "\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "#optimizer\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "os.mkdir(\"/kaggle\")\n",
    "os.mkdir(\"/kaggle/utkface/\")\n",
    "os.mkdir(\"/kaggle/utkface/train/\")\n",
    "os.mkdir(\"/kaggle/utkface/test/\")\n",
    "os.mkdir(\"/kaggle/utkface/valid/\")\n",
    "os.mkdir(\"/kaggle/workdir/\")\n",
    "\n",
    "all_classes = []\n",
    "l = 0\n",
    "for class_name in age_limits:\n",
    "    all_classes.append(class_name)\n",
    "    os.mkdir(\"/kaggle/utkface/train/\"+str(class_name)+\"/\")\n",
    "    os.mkdir(\"/kaggle/utkface/test/\"+str(class_name)+\"/\")\n",
    "    os.mkdir(\"/kaggle/utkface/valid/\"+str(class_name)+\"/\")\n",
    "'''\n",
    "\n",
    "path = \"UTKFace/\"\n",
    "for filename in os.listdir(path):\n",
    "    age = int(filename.split(\"_\")[0])\n",
    "    if age in age_limits:\n",
    "        class_name = str(age)\n",
    "        shutil.copy2(path+filename, \"/kaggle/utkface/train/\"+class_name+\"/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_filename in os.listdir(\"/kaggle/utkface/train\"):\n",
    "    number_images = len(next(os.walk(\"/kaggle/utkface/train/\"+class_filename))[2])\n",
    "    number_test_images = int(test_split * number_images)\n",
    "    number_valid_images = int(valid_split * number_images)\n",
    "    all_images_filenames = next(os.walk(\"/kaggle/utkface/train/\"+class_filename))[2]\n",
    "    #select random test images from all images\n",
    "    test_images_filenames = random.sample(all_images_filenames, number_test_images)\n",
    "    #remove test images from all images\n",
    "    all_images_filenames = [ img for img in all_images_filenames if img not in test_images_filenames]\n",
    "    #select random valid images from all images\n",
    "    valid_images_filenames = random.sample(all_images_filenames, number_valid_images)\n",
    "    for x in test_images_filenames:\n",
    "        shutil.move(\"/kaggle/utkface/train/\"+class_filename+\"/\"+x, \"/kaggle/utkface/test/\"+class_filename+\"/\"+x)\n",
    "    for x in valid_images_filenames:\n",
    "        shutil.move(\"/kaggle/utkface/train/\"+class_filename+\"/\"+x, \"/kaggle/utkface/valid/\"+class_filename+\"/\"+x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmention_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=(-30, 30)),\n",
    "    transforms.RandomGrayscale(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5964, 0.4567, 0.3910], [0.1257, 0.1144, 0.1206])\n",
    "])\n",
    "\n",
    "transform_size_normalize = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    transforms.Normalize([0.5964, 0.4567, 0.3910], [0.1257, 0.1144, 0.1206])\n",
    "])\n",
    "\n",
    "transform_size = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = torchvision.datasets.ImageFolder('/kaggle/utkface/train/', transform=augmention_transforms)\n",
    "valid_ds = torchvision.datasets.ImageFolder('/kaggle/utkface/valid/', transform=transform_size_normalize)\n",
    "test_ds = torchvision.datasets.ImageFolder('/kaggle/utkface/test/', transform=transform_size_normalize)\n",
    "printing_data = torchvision.datasets.ImageFolder('/kaggle/utkface/test/', transform=transform_size)\n",
    "\n",
    "train_dataloader = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "test_dataloader  = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "valid_dataloader = data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "printing_dataloader = data.DataLoader(printing_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader 조사로부터 내가 확인하고 싶었던 것은\n",
    "1. X, y의 shape. (3, 244, 244) 이미지를 입력받아 스칼라값(0~100 range)을 배출한다. 이미지 전처리 방법은 아직 잘 모르겠어서 논문을 참고해봐야겠다.\n",
    " range가 명확하게 보이지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_pdf_age(mean, std, max_age=101):\n",
    "    norm_pdf = norm(loc = mean, scale = std)\n",
    "    p = torch.tensor(norm_pdf.pdf(torch.tensor(list(range(max_age)))))\n",
    "    return p/torch.sum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv(in_channels, out_channels, kerner_size=3, stride=1, padding=1):\n",
    "    out_channels = int(out_channels)\n",
    "    in_channels = int(in_channels)\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kerner_size, stride, padding, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(True),\n",
    "    )\n",
    "\n",
    "class DLDLv2(nn.Module):\n",
    "    def __init__(self, max_age=101, c=0.5):\n",
    "        super(DLDLv2, self).__init__()\n",
    "        self.conv1 = Conv(3, 64*c)\n",
    "        self.conv2 = Conv(64*c, 64*c)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = Conv(64*c, 128*c)\n",
    "        self.conv4 = Conv(128*c, 128*c)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = Conv(128*c, 256*c)\n",
    "        self.conv6 = Conv(256*c, 256*c)\n",
    "        self.conv7 = Conv(256*c, 256*c)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.conv8 = Conv(256*c, 512*c)\n",
    "        self.conv9 = Conv(512*c, 512*c)\n",
    "        self.conv10 = Conv(512*c, 512*c)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.conv11 = Conv(512*c, 512*c)\n",
    "        self.conv12 = Conv(512*c, 512*c)\n",
    "        self.conv13 = Conv(512*c, 512*c)\n",
    "        self.HP = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(int(512*c), max_age),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.ages = torch.tensor(list(range(max_age))).t().float()\n",
    "        self.device = \"cpu\"\n",
    "        self.transform_normalize = torchvision.transforms.Compose([\n",
    "            transforms.Normalize([0.5964, 0.4567, 0.3910], [0.1257, 0.1144, 0.1206])\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x) \n",
    "        x = self.HP(x)\n",
    "        x = x.view((x.size(0), -1))\n",
    "        x = self.fc1(x.view((x.size(0), -1)))\n",
    "        x = F.normalize(x, p=1, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def to(self, device):\n",
    "        module = super(DLDLv2, self).to(device)\n",
    "        module.ages = self.ages.to(device)\n",
    "        self.device = device\n",
    "        return module\n",
    "\n",
    "    #train model on a batch\n",
    "    def train_batch(self, x, y):\n",
    "        x  = x.to(device)\n",
    "        b_x = Variable(x)\n",
    "        outputs = self.forward(b_x)\n",
    "        age = torch.matmul(outputs,self.ages)\n",
    "        pdf = []\n",
    "        for z in y:\n",
    "            label_distributions =  normal_pdf_age(z, 5)\n",
    "            pdf.append(label_distributions)\n",
    "        pdf = torch.stack(pdf)\n",
    "        pdf = pdf.to(device)\n",
    "        y = y.to(device)\n",
    "        b_y = Variable(y)\n",
    "        return custom_loss(outputs, age, b_y, pdf)\n",
    "    \n",
    "    \n",
    "    #predict age of a batch\n",
    "    def predict_age(self, x):\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.forward(x)\n",
    "        return torch.matmul(outputs,self.ages)\n",
    "        \n",
    "    def predict_age_normalize(self, x):\n",
    "        x = self.transform_normalize(x)\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.forward(x)\n",
    "        return torch.matmul(outputs,self.ages), outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.00 GiB total capacity; 2.60 GiB already allocated; 0 bytes free; 2.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Seungwon Jang\\Desktop\\Projects\\VScode Workspace\\dldlv2\\main.ipynb 셀 10\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), betas\u001b[39m=\u001b[39m(BETA1, BETA2), lr\u001b[39m=\u001b[39mLEARNING_RATE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m num_training_steps \u001b[39m=\u001b[39m EPOCHS \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader)\n",
      "\u001b[1;32mc:\\Users\\Seungwon Jang\\Desktop\\Projects\\VScode Workspace\\dldlv2\\main.ipynb 셀 10\u001b[0m in \u001b[0;36mDLDLv2.to\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(DLDLv2, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     module\u001b[39m.\u001b[39mages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mages\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X23sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    904\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    905\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    577\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 578\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    580\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    581\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    583\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    589\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    577\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 578\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    580\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    581\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    583\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    589\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 601\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    602\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    903\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    904\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 905\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.00 GiB total capacity; 2.60 GiB already allocated; 0 bytes free; 2.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "compression_rate = 0.5\n",
    "model = DLDLv2(max_age, compression_rate)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/kaggle/input/convert-pretrained-thinage-to-torchmodel/ThinAgeNet-ChaLearn16.pt\"))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(BETA1, BETA2), lr=LEARNING_RATE)\n",
    "num_training_steps = EPOCHS * len(train_dataloader)\n",
    "lr_scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "#define loss functions\n",
    "loss_l1_fc = nn.L1Loss(reduction='mean')\n",
    "#get age tensor\n",
    "ages = torch.tensor(list(range(max_age+1))[1:]).to(device).t().float()\n",
    "\n",
    "def custom_loss(logits, age, label_age, label_distribution, y=1, max_age=101):\n",
    "    batchsize = len(label_age)\n",
    "    #l1 loss\n",
    "    l1_loss = torch.sum(torch.abs(age-label_age))/batchsize\n",
    "\n",
    "    #KL loss\n",
    "    log_logits = torch.log(logits)\n",
    "    kl_loss = (-1 * torch.sum(torch.diag(torch.matmul(log_logits, label_distribution.float().t()))))/batchsize\n",
    "    \n",
    "    #combined loss\n",
    "    combined_loss = y * l1_loss + kl_loss\n",
    "    \n",
    "    return combined_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 3.00 GiB total capacity; 2.60 GiB already allocated; 0 bytes free; 2.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Seungwon Jang\\Desktop\\Projects\\VScode Workspace\\dldlv2\\main.ipynb 셀 11\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m test_loss_length \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m (x, y) \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     loss, l1_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_batch(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m#track loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     training_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m l1_loss\u001b[39m.\u001b[39mdata\n",
      "\u001b[1;32mc:\\Users\\Seungwon Jang\\Desktop\\Projects\\VScode Workspace\\dldlv2\\main.ipynb 셀 11\u001b[0m in \u001b[0;36mDLDLv2.train_batch\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m x  \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m b_x \u001b[39m=\u001b[39m Variable(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(b_x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m age \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(outputs,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mages)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m pdf \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32mc:\\Users\\Seungwon Jang\\Desktop\\Projects\\VScode Workspace\\dldlv2\\main.ipynb 셀 11\u001b[0m in \u001b[0;36mDLDLv2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Seungwon%20Jang/Desktop/Projects/VScode%20Workspace/dldlv2/main.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Seungwon Jang\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    441\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    442\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 443\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    444\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 3.00 GiB total capacity; 2.60 GiB already allocated; 0 bytes free; 2.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "training_loss_history, test_loss_history = [], []\n",
    "\n",
    "model.train()\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    #track trianing loss\n",
    "    training_loss = 0\n",
    "    training_loss_length = 0\n",
    "    \n",
    "    #track test loss\n",
    "    test_loss = 0\n",
    "    test_loss_length = 0\n",
    "\n",
    "    for (x, y) in train_dataloader:\n",
    "        loss, l1_loss = model.train_batch(x, y)\n",
    "        \n",
    "        #track loss\n",
    "        training_loss += l1_loss.data\n",
    "        training_loss_length += 1\n",
    "        \n",
    "        #back propagate and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    #testing accuracy\n",
    "    for (x, y) in test_dataloader:\n",
    "        #predict age\n",
    "        age = model.predict_age(x)\n",
    "        \n",
    "        #compute and track loss\n",
    "        y = y.to(device)\n",
    "        l1_loss = loss_l1_fc(age, y)\n",
    "        \n",
    "        #track loss\n",
    "        test_loss += l1_loss.data\n",
    "        test_loss_length += 1\n",
    "        \n",
    "    \n",
    "    \n",
    "    training_loss_history.append(training_loss/training_loss_length)\n",
    "    test_loss_history.append(test_loss/test_loss_length)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"epoch:         {}\".format(epoch))\n",
    "        print(\"training loss: {:6.4f}\".format(training_loss/training_loss_length))\n",
    "        print(\"testing loss:  {:6.4f}\".format(test_loss/test_loss_length))\n",
    "        print(\"-------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f616ee28b30047d2255d8b703cc1581ff852649e2c65f80f38a570ed15f5249"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
